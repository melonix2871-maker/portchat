<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>PortChat</title>
  <style>
    :root { --bg: #0f0f17; --text: #e0e0ff; --user: #3a3a7a; --bot: #1e3a5f; --input: #1a1a2e; }
    body { margin:0; font-family: system-ui; background:var(--bg); color:var(--text); height:100vh; display:flex; flex-direction:column; }
    header { padding:15px; background:#0a0a14; border-bottom:1px solid #333; text-align:center; font-weight:bold; }
    #chat { flex:1; overflow-y:auto; padding:20px; display:flex; flex-direction:column; gap:16px; }
    .msg { max-width:80%; padding:14px 18px; border-radius:18px; line-height:1.5; white-space:pre-wrap; }
    .user { align-self:flex-end; background:var(--user); border-bottom-right-radius:4px; }
    .bot { align-self:flex-start; background:var(--bot); border-bottom-left-radius:4px; }
    #input-area { padding:15px; background:#0a0a14; border-top:1px solid #333; display:flex; gap:12px; }
    #user-input { flex:1; padding:14px 20px; background:var(--input); border:none; border-radius:30px; color:white; font-size:16px; outline:none; resize:none; }
    button { padding:0 24px; background:#6366f1; color:white; border:none; border-radius:30px; font-weight:bold; cursor:pointer; }
    button:disabled { background:#444; cursor:not-allowed; }
    #status { text-align:center; padding:10px; color:#a0a0ff; font-size:14px; }
  </style>
</head>
<body>

<header>PortChat â€” 100% Local AI (Llama 3.2 3B)</header>
<div id="status">Initializing WebGPU & downloading model... (3â€“10 min first time)</div>

<div id="chat"></div>

<div id="input-area">
  <textarea id="user-input" placeholder="Type a message..." rows="1"></textarea>
  <button id="send" disabled>Send</button>
</div>

<script type="module">
  import { CreateMLCEngine } from "https://cdn.jsdelivr.net/npm/@mlc-ai/web-llm@0.2.48/+esm";

  const MODEL = "Llama-3.2-3B-Instruct-q4f16_1-MLC";   // â† Super fast & smart
  // Other great options:
  // "Phi-3.5-mini-instruct-q4f16_1-MLC"     â† even faster on weak hardware
  // "Gemma-2-2b-it-q4f16_1-MLC"             â† tiny & quick

  let engine = null;
  let messages = [{ role: "system", content: "You are a helpful AI assistant." }];

  const chatDiv = document.getElementById("chat");
  const input = document.getElementById("user-input");
  const sendBtn = document.getElementById("send");
  const status = document.getElementById("status");

  input.addEventListener("input", () => {
    input.style.height = "auto";
    input.style.height = input.scrollHeight + "px";
  });

  input.addEventListener("keydown", e => {
    if (e.key === "Enter" && !e.shiftKey) {
      e.preventDefault();
      sendMessage();
    }
  });

  sendBtn.addEventListener("click", sendMessage);

  async function sendMessage() {
    const text = input.value.trim();
    if (!text || !engine) return;

    addMessage("user", text);
    input.value = "";
    input.style.height = "auto";
    sendBtn.disabled = true;

    messages.push({ role: "user", content: text });

    const replyDiv = addMessage("bot", "");
    let fullReply = "";

    try {
      const stream = await engine.chat.completions.create({
        messages,
        stream: true,
        temperature: 0.7,
        max_gen_len: 1024,
      });

      for await (const chunk of stream) {
        const delta = chunk.choices[0]?.delta?.content || "";
        fullReply += delta;
        replyDiv.textContent = fullReply;
        chatDiv.scrollTop = chatDiv.scrollHeight;
      }

      messages.push({ role: "assistant", content: fullReply });
    } catch (err) {
      replyDiv.textContent += "\n\nError: " + err.message;
    }

    sendBtn.disabled = false;
    input.focus();
  }

  function addMessage(role, content) {
    const div = document.createElement("div");
    div.className = "msg " + (role === "user" ? "user" : "bot");
    div.textContent = content;
    chatDiv.appendChild(div);
    chatDiv.scrollTop = chatDiv.scrollHeight;
    return div;
  }

  // =============== START ENGINE ===============
  (async () => {
    try {
      status.textContent = "Downloading model... (this may take 5-15 minutes first time)";

      engine = await CreateMLCEngine(
        MODEL,
        {
          initProgressCallback: (progress) => {
            status.textContent = `${progress.text} (${Math.round(progress.progress * 100)}%)`;
          },
        }
      );

      status.textContent = "Model loaded! You can chat now ðŸš€";
      sendBtn.disabled = false;
      input.focus();

      addMessage("bot", "Hey Romeo! ðŸ‘‹\nI'm running entirely in your browser â€” no data leaves your device.\nAsk me anything!");
    } catch (err) {
      status.textContent = "Failed: " + err.message;
      console.error(err);
    }
  })();
</script>

</body>
</html>
